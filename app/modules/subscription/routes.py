# routes.py

from flask import Blueprint, render_template, jsonify, Response, make_response, request, url_for, abort
from flask_login import login_required, current_user
# å¼•å…¥ update_node_custom_name ç”¨äº DB èŠ‚ç‚¹æ”¹å
from app.utils.db_manager import get_all_nodes, update_node_details, get_config, set_config, update_node_custom_name
from app.utils.scheduler import scheduler
import os
import sys         # ç”¨äºåˆ¤æ–­æ‰“åŒ…ç¯å¢ƒ
import shutil      # ç”¨äºå¤åˆ¶æ–‡ä»¶æ¢å¤æ¨¡æ¿
import requests    # ç”¨äºä¸‹è½½è®¢é˜…
from app.utils.path_helper import get_external_config_path # å¼•å…¥åˆ›å»ºçš„è·¯å¾„å¤„ç†å·¥å…·
import json
import base64
import time
from datetime import datetime
import urllib.parse
import uuid
from io import BytesIO

from collections import defaultdict

from ruamel.yaml import YAML
from .link_parser import parse_proxy_link, get_emoji_flag, extract_nodes_from_content, fix_link_ipv6

bp = Blueprint('subscription', __name__, url_prefix='/subscription', template_folder='templates')

SUBSCRIPTION_CONFIG_KEY = 'external_subscriptions'
LEGACY_SUB_LIST_KEY = 'external_sub_urls'
LEGACY_SUB_SINGLE_KEY = 'external_sub_url'

def _normalize_subscription_entry(data, order_index=0):
    if not isinstance(data, dict):
        data = {'url': str(data) if data else ''}
    entry = {
        'id': data.get('id') or str(uuid.uuid4()),
        'name': (data.get('name') or '').strip(),
        'url': (data.get('url') or data.get('link') or '').strip(),
        'note': (data.get('note') or '').strip(),
        'enabled': bool(data.get('enabled', True)),
        'last_status': data.get('last_status'),
        'last_message': data.get('last_message', ''),
        'last_synced_at': data.get('last_synced_at'),
        'last_trigger': data.get('last_trigger', ''),
        'order': data.get('order', order_index)
    }
    return entry

def load_subscription_entries():
    entries = []
    raw = get_config(SUBSCRIPTION_CONFIG_KEY, default='')
    if raw:
        try:
            parsed = json.loads(raw)
            if isinstance(parsed, list):
                for idx, item in enumerate(parsed):
                    entries.append(_normalize_subscription_entry(item, idx))
        except Exception as e:
            print(f"Error parsing {SUBSCRIPTION_CONFIG_KEY}: {e}")

    if not entries:
        legacy_raw = get_config(LEGACY_SUB_LIST_KEY, default='')
        legacy_list = []
        if legacy_raw:
            try:
                parsed = json.loads(legacy_raw)
                if isinstance(parsed, list):
                    legacy_list = [str(x) for x in parsed]
            except Exception:
                legacy_list = [line.strip() for line in legacy_raw.splitlines() if line.strip()]
        else:
            single = get_config(LEGACY_SUB_SINGLE_KEY, default='')
            if single:
                legacy_list = [line.strip() for line in single.splitlines() if line.strip()]

        for idx, url in enumerate(legacy_list):
            entries.append(_normalize_subscription_entry({'url': url}, idx))

    # é‡æ–°ç¼–å· orderï¼Œé¿å…å‡ºç°é‡å¤
    for idx, item in enumerate(entries):
        item['order'] = idx
    return entries

def save_subscription_entries(entries):
    prepared = []
    for idx, item in enumerate(entries):
        normalized = _normalize_subscription_entry(item, idx)
        prepared.append(normalized)
    string_list = [i['url'] for i in prepared if i.get('url')]
    # æŒä¹…åŒ–ä¸»é…ç½®
    saved = set_config(SUBSCRIPTION_CONFIG_KEY, json.dumps(prepared, ensure_ascii=False), description='è®¢é˜…ç®¡ç†-å¤šè®¢é˜…é…ç½®')
    # å…¼å®¹è€å­—æ®µ
    set_config(LEGACY_SUB_LIST_KEY, json.dumps(string_list, ensure_ascii=False), description='è®¢é˜…ç®¡ç†-è®¢é˜…åˆ—è¡¨(å…¼å®¹)')
    set_config(LEGACY_SUB_SINGLE_KEY, string_list[0] if string_list else '', description='è®¢é˜…ç®¡ç†-å•è®¢é˜…(å…¼å®¹)')
    return saved

def refresh_auto_sync_job():
    try:
        if not getattr(scheduler, 'app', None):
            return
        enabled = str(get_config('SUBSCRIPTION_AUTO_SYNC_ENABLED', '0')).lower() in ['1', 'true', 'yes']
        try:
            interval = max(int(get_config('SUBSCRIPTION_AUTO_SYNC_INTERVAL_MINUTES', 30)), 1)
        except (TypeError, ValueError):
            interval = 30

        if enabled:
            scheduler.add_job(
                id='subscription_auto_sync',
                func=auto_sync_subscriptions_job,
                trigger='interval',
                minutes=interval,
                max_instances=1,
                replace_existing=True,
                args=[]
            )
        else:
            if scheduler.get_job('subscription_auto_sync'):
                scheduler.remove_job('subscription_auto_sync')
    except Exception as e:
        print(f"[Subscription-AutoSync] è°ƒæ•´ä»»åŠ¡å¤±è´¥: {e}")

# ---------------------------------------------------------
# æ–°å¢è¾…åŠ©å‡½æ•°ï¼šè‡ªæ„ˆæœºåˆ¶
# ---------------------------------------------------------
def check_and_restore_templates(target_dir):
    """
    è‡ªæ„ˆåŠŸèƒ½ï¼šæ£€æŸ¥å¤–éƒ¨ç›®å½•æ˜¯å¦ç¼ºå¤±æ¨¡æ¿æ–‡ä»¶ï¼Œå¦‚æœç¼ºå¤±åˆ™ä» exe å†…éƒ¨æ¢å¤
    """
    # ä»…åœ¨æ‰“åŒ…ç¯å¢ƒ (Frozen) ä¸‹æ‰§è¡Œæ¢å¤é€»è¾‘
    # å¼€å‘ç¯å¢ƒä¸‹ sys.frozen ä¸º Falseï¼Œç›´æ¥ä½¿ç”¨æºç æ–‡ä»¶ï¼Œä¸éœ€è¦æ¢å¤
    if not getattr(sys, 'frozen', False):
        return

    # å†…ç½®èµ„æºçš„è·¯å¾„ (ç”± PyInstaller è§£å‹åœ¨ _MEIPASS/bundled_templates)
    # è¿™ä¸ªè·¯å¾„å¯¹åº”æˆ‘ä»¬åœ¨ .spec æ–‡ä»¶é‡Œå®šä¹‰çš„ target_dir
    base_path = sys._MEIPASS
    source_dir = os.path.join(base_path, 'bundled_templates')
    
    if not os.path.exists(source_dir):
        # å¦‚æœå†…ç½®ç›®å½•éƒ½ä¸å­˜åœ¨ï¼Œè¯´æ˜æ‰“åŒ…æœ‰é—®é¢˜ï¼Œè·³è¿‡é˜²æ­¢æŠ¥é”™
        return

    # éœ€è¦æ£€æŸ¥çš„å…³é”®æ–‡ä»¶åˆ—è¡¨ (ä¸ spec æ–‡ä»¶ä¸­æ‰“åŒ…çš„ä¸€è‡´)
    critical_files = [
        'clash_meta.yaml', 
        'customize.list', 
        'direct.list', 
        'install-singbox.sh'
    ]
    
    for filename in critical_files:
        target_file = os.path.join(target_dir, filename)
        # å¦‚æœç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨ (ç”¨æˆ·è¯¯åˆ ï¼Œæˆ–é¦–æ¬¡è¿è¡Œ)ï¼Œåˆ™ä»å†…ç½®èµ„æºå¤åˆ¶
        if not os.path.exists(target_file):
            source_file = os.path.join(source_dir, filename)
            if os.path.exists(source_file):
                try:
                    shutil.copy2(source_file, target_file)
                    print(f"[Auto-Restore] Restored missing file: {filename}")
                except Exception as e:
                    print(f"[Error] Failed to restore {filename}: {e}")

# ---------------------------------------------------------
# ä¸»è·¯å¾„å‡½æ•°
# ---------------------------------------------------------
def get_nodes_dir():
    """
    è·å–èŠ‚ç‚¹é…ç½®æ–‡ä»¶å­˜å‚¨ç›®å½•
    å¢åŠ æ‰“åŒ…ç¯å¢ƒåˆ¤æ–­é€»è¾‘ + è‡ªæ„ˆé€»è¾‘
    """
    if getattr(sys, 'frozen', False):
        # [æ‰“åŒ…ç¯å¢ƒ]
        # å¦‚æœæ˜¯ exe è¿è¡Œï¼Œå¼ºåˆ¶å®šå‘åˆ° exe åŒçº§ç›®å½•ä¸‹çš„ 'nodes' æ–‡ä»¶å¤¹
        nodes_dir = get_external_config_path('nodes')
    else:
        # [å¼€å‘ç¯å¢ƒ]
        # ä¿æŒåŸæ ·ï¼ŒæŒ‡å‘ app/subscription/nodes
        current_dir = os.path.dirname(os.path.abspath(__file__))
        nodes_dir = os.path.join(current_dir, 'nodes')

    # 1. ç¡®ä¿ç›®å½•å­˜åœ¨
    if not os.path.exists(nodes_dir):
        try: os.makedirs(nodes_dir)
        except OSError as e: print(f"Error creating nodes dir: {e}")
    
    # 2. æ£€æŸ¥å¹¶æ¢å¤ç¼ºå¤±çš„æ¨¡æ¿æ–‡ä»¶
    # è¿™ä¸€æ­¥ä¿è¯äº†å³ä½¿å¤–éƒ¨ nodes æ–‡ä»¶å¤¹æ˜¯ç©ºçš„ï¼Œç¨‹åºå¯åŠ¨åä¹Ÿä¼šè‡ªåŠ¨æŠŠ
    # install-singbox.sh ç­‰æ–‡ä»¶é‡Šæ”¾å‡ºæ¥
    check_and_restore_templates(nodes_dir)
    
    return nodes_dir

# ---------------------------------------------------------
# 2. æœ¬åœ°èŠ‚ç‚¹ç®¡ç†å·¥å…· & æ ¸å¿ƒåŒæ­¥é€»è¾‘
# ---------------------------------------------------------
LOCAL_NODES_FILE = 'local_nodes.json'

def get_local_nodes_path():
    return os.path.join(get_nodes_dir(), LOCAL_NODES_FILE)

def load_local_nodes_raw():
    """
    [åº•å±‚å‡½æ•°] ä»…è¯»å–åŸå§‹ JSON æ•°æ®ï¼Œä¸è¿›è¡Œä¸šåŠ¡é€»è¾‘å¤„ç†
    """
    path = get_local_nodes_path()
    if not os.path.exists(path): return []
    try:
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except: return []

# å»ºç«‹åˆ«åå…¼å®¹æ—§ä»£ç è°ƒç”¨
load_local_nodes = load_local_nodes_raw

def save_local_nodes(nodes):
    """ä¿å­˜èŠ‚ç‚¹åˆ—è¡¨åˆ° JSON"""
    try:
        # ä¿å­˜å‰æŒ‰ sort_index æ’åºï¼Œä¿æŒæ–‡ä»¶æ•´æ´
        nodes.sort(key=lambda x: x.get('sort_index', 9999))
        with open(get_local_nodes_path(), 'w', encoding='utf-8') as f:
            json.dump(nodes, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"Error saving local nodes: {e}")
        return False

def merge_db_to_local_json():
    """
    å°†æ•°æ®åº“èŠ‚ç‚¹åŒæ­¥åˆ°æœ¬åœ° JSON
    ä¿®æ”¹ç‚¹ï¼šå°† DB èŠ‚ç‚¹çš„ is_fixed æ”¹ä¸º Falseï¼Œå…è®¸å‰ç«¯æ‹–æ‹½æ”¹å˜åˆ†ç»„
    """
    db_nodes = get_all_nodes()
    local_nodes = load_local_nodes_raw()
    
    local_map = {n['uuid']: n for n in local_nodes}
    active_db_uuids = set()
    has_changes = False

    # --- 1. åŒæ­¥ DB èŠ‚ç‚¹ ---
    for db_node in db_nodes:
        uuid_str = str(db_node.uuid)
        active_db_uuids.add(uuid_str)
        
        # è·å– DB æƒå¨æ•°æ®
        db_name = db_node.custom_name or db_node.name
        links = db_node.get_links_dict()
        r_type = db_node.routing_type if db_node.routing_type is not None else -1
        region = db_node.region or 'DB'

        if uuid_str in local_map:
            # [æ›´æ–°]
            node = local_map[uuid_str]
            
            updates = {
                'name': db_name,
                'links': links,
                'routing_type': r_type,
                'region': region,
                'origin': 'db',
                'is_fixed': False  # å…è®¸ DB èŠ‚ç‚¹è¢«æ‹–æ‹½ç§»åŠ¨
            }
            
            for k, v in updates.items():
                if node.get(k) != v:
                    node[k] = v
                    has_changes = True
            
            if 'sort_index' not in node:
                node['sort_index'] = 9999
                has_changes = True
                
        else:
            # [æ–°å¢]
            new_node = {
                "uuid": uuid_str,
                "name": db_name,
                "links": links,
                "routing_type": r_type,
                "region": region,
                "origin": "db",
                "is_fixed": False, # å…è®¸ DB èŠ‚ç‚¹è¢«æ‹–æ‹½ç§»åŠ¨
                "sort_index": 99999
            }
            local_nodes.append(new_node)
            has_changes = True

    # --- 2. æ¸…ç†å¤±æ•ˆèŠ‚ç‚¹ ---
    final_nodes = []
    for node in local_nodes:
        is_db_node = node.get('origin') == 'db'
        
        if is_db_node and node['uuid'] not in active_db_uuids:
            has_changes = True
            continue 
            
        if not is_db_node:
            if node.get('origin') not in ['local', 'sub']:
                node['origin'] = 'local'
                node['is_fixed'] = False 
                has_changes = True

        final_nodes.append(node)
    
    if has_changes:
        save_local_nodes(final_nodes)
        return final_nodes
    
    return final_nodes
# ---------------------------------------------------------
# 3. é…ç½®æ–‡ä»¶ç”Ÿæˆé€»è¾‘ (è¯»å–ç»Ÿä¸€æ•°æ®æº)
# ---------------------------------------------------------
def sync_nodes_to_files():
    """
    ç”Ÿæˆ 0.yaml å’Œ 1.yaml
    å¼ºåˆ¶å°† YAML ä¸­çš„ name å­—æ®µé‡å†™ä¸º 'Flag Proto-Name' æ ¼å¼
    """
    # 1. è·å–æœ€æ–°åˆå¹¶åçš„èŠ‚ç‚¹åˆ—è¡¨
    all_nodes = merge_db_to_local_json()
    
    # 2. æŒ‰ sort_index æ’åº
    all_nodes.sort(key=lambda x: x.get('sort_index', 0))

    proxies_map = {0: [], 1: []}
    count_summary = {0: 0, 1: 0}

    for node in all_nodes:
        r_type = node.get('routing_type', -1)
        if r_type not in proxies_map: continue
        
        links = node.get('links', {})
        node_name = node.get('name', 'Unknown')
        origin = node.get('origin', 'local')
        region = node.get('region')
        
        for proto, link in links.items():
            if link and link.strip():
                # å‘½åæ ¼å¼å¼ºåˆ¶è°ƒæ•´
                # 1. ç¡®å®šå›½æ——
                # å¢åŠ å¯¹ 'sub' (å¤–éƒ¨è®¢é˜…) çš„åˆ¤æ–­ï¼Œæ˜¾ç¤ºäº‘æœµå›¾æ ‡
                if origin == 'db':
                    flag = get_emoji_flag(region)
                    name_prefix = f"{proto.lower()}-"   # DB èŠ‚ç‚¹å¿…é¡»å¸¦åè®®å‰ç¼€
                elif origin == 'sub':
                    flag = ''  # å¤–éƒ¨è®¢é˜…ä¸æ˜¾ç¤ºå›½æ——æˆ–æ ‡å¿—ï¼Œä¿ç•™åŸå§‹åç§°
                    name_prefix = ""    # å¤–éƒ¨è®¢é˜…èŠ‚ç‚¹ï¼šä¸å¸¦ä»»ä½•å‰ç¼€
                else:
                    flag = 'ğŸ“' # æœ¬åœ°æ‰‹å¡«æ ‡å¿—
                    name_prefix = f"{proto.lower()}-"
                
                # 2. æ„é€ å¼ºåˆ¶åç§°ï¼šFlag Protocol-Name (ä¾‹å¦‚: ğŸ‡¸ğŸ‡¬ hy2-SG-NAT1)
                display_name = f"{flag} {name_prefix}{node_name}".strip()
                
                # 3. è°ƒç”¨è§£æå™¨
                # æ³¨æ„ï¼šè™½ç„¶ä¼ å…¥äº† display_nameï¼Œä½†è§£æå™¨å¯èƒ½ä¼šä¼˜å…ˆè¯»å– link ä¸­çš„ #hash
                proxy_dict = parse_proxy_link(link.strip(), display_name, region)
                
                if proxy_dict:
                    # æ— è®º parse_proxy_link è¿”å›çš„ name æ˜¯ä»€ä¹ˆï¼ˆå¯èƒ½æ˜¯æ—§çš„åç¼€æ ¼å¼ï¼‰ï¼Œ
                    # è¿™é‡Œå¼ºåˆ¶å°†å…¶è¦†ç›–ä¸ºæˆ‘ä»¬åˆšåˆšæ„é€ çš„å‰ç¼€æ ¼å¼ã€‚
                    proxy_dict['name'] = display_name
                    proxies_map[r_type].append(proxy_dict)
                    count_summary[r_type] += 1

    # --- å†™å…¥ YAML ---
    nodes_dir = get_nodes_dir()
    yaml = YAML()
    yaml.preserve_quotes = True
    yaml.indent(mapping=2, sequence=2, offset=0)
    # 4096æ˜¯ä¸ºäº†ç»„åˆæ¨¡æ¿æ—¶å€™ä¸è¢«æˆªæ–­
    yaml.width = 4096

    try:
        with open(os.path.join(nodes_dir, '0.yaml'), 'w', encoding='utf-8') as f:
            yaml.dump({'proxies': proxies_map[0]}, f)
        with open(os.path.join(nodes_dir, '1.yaml'), 'w', encoding='utf-8') as f:
            yaml.dump({'proxies': proxies_map[1]}, f)  
        return True, f"åŒæ­¥æˆåŠŸ: ç›´è¿ {count_summary[0]}, è½åœ° {count_summary[1]}"
    except Exception as e:
        return False, f"å†™å…¥å¤±è´¥: {str(e)}"

# ---------------------------------------------------------
# 4. ç»Ÿè®¡é€»è¾‘
# ---------------------------------------------------------
def get_stats_data():
    """è·å–ç»Ÿè®¡ä¿¡æ¯ï¼šä¿®æ”¹ä¸ºç»Ÿä¸€ä»åˆå¹¶åˆ—è¡¨è·å–"""
    # è§¦å‘åŒæ­¥ï¼Œè·å–å…¨é‡æ•°æ®
    all_nodes = merge_db_to_local_json()

    stats = {
        "total": len(all_nodes),
        "direct": 0,
        "land": 0,
        "blocked": 0,
        "protocols": {}
    }

    PROTOCOL_NORMALIZE_MAP = {
        'hy2': 'Hysteria2', 'hysteria2': 'Hysteria2',
        'ss': 'Shadowsocks', 'shadowsocks': 'Shadowsocks',
        'vless': 'VLESS', 'vmess': 'VMess',
        'trojan': 'Trojan', 'tuic': 'TUIC', 'socks5': 'Socks5'
    }

    for node in all_nodes:
        r_type = node.get('routing_type', -1)
        if r_type == 0: stats['direct'] += 1
        elif r_type == 1: stats['land'] += 1
        else: stats['blocked'] += 1
        
        links = node.get('links', {})
        for proto, link in links.items():
            if link and link.strip():
                key = proto.lower()
                normalized = PROTOCOL_NORMALIZE_MAP.get(key, proto)
                stats['protocols'][normalized] = stats['protocols'].get(normalized, 0) + 1
    
    return stats

# ---------------------------------------------------------
# æ•°æ®åº“å­˜å‚¨å¹¶å¤„ç†è®¢é˜…è®¾ç½® (è¾…åŠ©å‡½æ•°ä¿æŒä¸å˜)
# ---------------------------------------------------------
def get_sub_settings():
    entries = load_subscription_entries()
    url_list = [item['url'] for item in entries if item.get('url')]
    auto_enabled = str(get_config('SUBSCRIPTION_AUTO_SYNC_ENABLED', '0')).lower() in ['1', 'true', 'yes', 'on']
    try:
        auto_interval = int(get_config('SUBSCRIPTION_AUTO_SYNC_INTERVAL_MINUTES', 30))
        if auto_interval < 1:
            auto_interval = 1
    except (TypeError, ValueError):
        auto_interval = 30
    return {
        'fixed_domain': get_config('fixed_domain', default=''),
        'api_token': get_config('api_token', default='default'),
        'external_subscriptions': entries,
        'external_sub_urls': url_list,
        'external_sub_url': '\n'.join(url_list),
        'sub_auto_enabled': auto_enabled,
        'sub_auto_interval': auto_interval
    }

def verify_request_token():
    token = request.args.get('token')
    settings = get_sub_settings()
    if token != settings.get('api_token', 'default'):
        abort(403, description="Invalid Access Token")

def get_base_url():
    settings = get_sub_settings()
    fixed = settings.get('fixed_domain', '').strip()
    if fixed: return fixed.rstrip('/')
    
    scheme = request.headers.get('X-Forwarded-Proto', request.scheme)
    host = request.headers.get('X-Forwarded-Host') or request.headers.get('Host') or request.host
    if ':' not in host and request.headers.get('X-Forwarded-Port'):
        host = f"{host}:{request.headers.get('X-Forwarded-Port')}"
    return f"{scheme}://{host}"

# ---------------------------------------------------------
# 5. è·¯ç”±è§†å›¾å‡½æ•°
# ---------------------------------------------------------
@bp.route('/')
@login_required
def manager():
    """è®¢é˜…ç®¡ç†ä¸»é¡µ"""
    stats = get_stats_data()
    settings = get_sub_settings()
    base_url = get_base_url()
    token = settings.get('api_token', 'default')
    
    clash_url = f"{base_url}/subscription/clash?token={token}"
    v2ray_url = f"{base_url}/subscription/base64/all?token={token}"
    script_url = f"{base_url}{url_for('subscription.download_singbox_script')}"
    callback_url = f"{base_url}{url_for('subscription.add_node_callback')}"
    
    return render_template('sub_manager.html', stats=stats, clash_url=clash_url, 
                           v2ray_url=v2ray_url, script_url=script_url, 
                           callback_url=callback_url, token=token, 
                           settings=settings, current_base_url=base_url)

@bp.route('/api/settings/update', methods=['POST'])
@login_required
def update_settings_api():
    """API: æ›´æ–°è®¾ç½®"""
    data = request.get_json()
    is_saved = False
    job_should_refresh = False
    if 'domain' in data:
        domain = data.get('domain', '').strip()
        if domain and not domain.startswith('http'): domain = 'http://' + domain
        if set_config('fixed_domain', domain, description='è®¢é˜…ç®¡ç†-å›ºå®šåŸŸå'): is_saved = True
    if 'api_token' in data:
        if set_config('api_token', data.get('api_token', '').strip(), description='è®¢é˜…ç®¡ç†-å®‰å…¨Token'): is_saved = True
    # è®¢é˜…åˆ—è¡¨ä¿å­˜ï¼šä¼˜å…ˆæ¥æ”¶ç»“æ„åŒ– sub_itemsï¼Œå…¶æ¬¡å…¼å®¹ sub_urls/sub_url
    new_entries_payload = None
    if isinstance(data.get('sub_items'), list):
        raw_items = data.get('sub_items')
        existing = {item['id']: item for item in load_subscription_entries()}
        prepared = []
        for idx, item in enumerate(raw_items):
            if not isinstance(item, dict):
                continue
            entry_id = item.get('id') or str(uuid.uuid4())
            base = existing.get(entry_id, {})
            prepared.append({
                'id': entry_id,
                'name': (item.get('name') or '').strip(),
                'url': (item.get('url') or '').strip(),
                'note': (item.get('note') or '').strip(),
                'enabled': bool(item.get('enabled', True)),
                'last_status': base.get('last_status'),
                'last_message': base.get('last_message', ''),
                'last_synced_at': base.get('last_synced_at'),
                'last_trigger': base.get('last_trigger'),
                'order': idx
            })
        new_entries_payload = prepared
    elif isinstance(data.get('sub_urls'), list):
        cleaned = [u.strip() for u in data.get('sub_urls') if isinstance(u, str) and u.strip()]
        new_entries_payload = [{
            'id': str(uuid.uuid4()),
            'name': '',
            'url': url,
            'enabled': True,
            'note': ''
        } for url in cleaned]
    elif 'sub_url' in data:
        raw = data.get('sub_url', '')
        cleaned = [u.strip() for u in raw.splitlines() if u.strip()]
        new_entries_payload = [{
            'id': str(uuid.uuid4()),
            'name': '',
            'url': url,
            'enabled': True,
            'note': ''
        } for url in cleaned]

    if new_entries_payload is not None:
        if save_subscription_entries(new_entries_payload):
            is_saved = True

    if 'sub_auto_enabled' in data:
        enabled_val = data.get('sub_auto_enabled')
        enabled = False
        if isinstance(enabled_val, bool):
            enabled = enabled_val
        elif isinstance(enabled_val, str):
            enabled = enabled_val.lower() in ['1', 'true', 'yes', 'on']
        elif isinstance(enabled_val, (int, float)):
            enabled = int(enabled_val) != 0
        if set_config('SUBSCRIPTION_AUTO_SYNC_ENABLED', 1 if enabled else 0, description='è®¢é˜…è‡ªåŠ¨åŒæ­¥å¼€å…³'):
            is_saved = True
            job_should_refresh = True

    if 'sub_auto_interval' in data:
        try:
            interval = max(int(data.get('sub_auto_interval')), 1)
            if set_config('SUBSCRIPTION_AUTO_SYNC_INTERVAL_MINUTES', interval, description='è®¢é˜…è‡ªåŠ¨åŒæ­¥é—´éš”(åˆ†)'):
                is_saved = True
                job_should_refresh = True
        except (TypeError, ValueError):
            pass

    if job_should_refresh:
        refresh_auto_sync_job()
    return jsonify({'status': 'success' if is_saved else 'error', 'message': 'è®¾ç½®å·²ä¿å­˜' if is_saved else 'ä¿å­˜å¤±è´¥'})

@bp.route('/api/token/refresh', methods=['POST'])
@login_required
def refresh_token_api():
    """API: åˆ·æ–° Token"""
    new_token = str(uuid.uuid4()).replace('-', '')[:16]
    if set_config('api_token', new_token, description='è®¢é˜…ç®¡ç†-å®‰å…¨Token'):
        return jsonify({'status': 'success', 'token': new_token, 'message': 'Token å·²åˆ·æ–°'})
    return jsonify({'status': 'error', 'message': 'åˆ·æ–°å¤±è´¥'}), 500

@bp.route('/clash')
def download_clash_config():
    """ä¸‹è½½ Clash é…ç½®æ–‡ä»¶"""
    verify_request_token()
    
    try:
        base_url = get_base_url()
        token = get_sub_settings().get('api_token', 'default')
        timestamp = int(time.time())
        path = os.path.join(get_nodes_dir(), 'clash_meta.yaml')
        
        if not os.path.exists(path): return "Error: Template not found.", 404
        
        yaml = YAML()
        yaml.preserve_quotes = True
        yaml.indent(mapping=2, sequence=4, offset=2)
        with open(path, 'r', encoding='utf-8') as f: config_data = yaml.load(f)
        
        # æ›´æ–° Provider URL
        if 'proxy-providers' in config_data:
            for name, p in config_data['proxy-providers'].items():
                if '0.yaml' in p.get('path', '') or '/raw/0' in p.get('url', '') or 'ä¸­è½¬' in name:
                    p['url'] = f"{base_url}/subscription/raw/0?token={token}&t={timestamp}"
                    p['interval'] = 300
                elif '1.yaml' in p.get('path', '') or '/raw/1' in p.get('url', '') or 'è½åœ°' in name:
                    p['url'] = f"{base_url}/subscription/raw/1?token={token}&t={timestamp}"
                    p['interval'] = 300
        
        if 'rule-providers' in config_data:
            for name, p in config_data['rule-providers'].items():
                if 'direct' in name or 'direct' in p.get('path', ''):
                    p['url'] = f"{base_url}/subscription/list/direct?token={token}&t={timestamp}"
                elif 'customize' in name or 'customize' in p.get('path', ''):
                    p['url'] = f"{base_url}/subscription/list/customize?token={token}&t={timestamp}"

        out = BytesIO()
        yaml.dump(config_data, out)
        resp = make_response(out.getvalue())
        resp.headers["Content-Disposition"] = "attachment; filename=clash_meta_config.yaml"
        resp.mimetype = "text/yaml; charset=utf-8"
        resp.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
        return resp
    except Exception as e: return f"Error: {str(e)}", 500

@bp.route('/install-singbox.sh')
def download_singbox_script():
    path = os.path.join(get_nodes_dir(), 'install-singbox.sh')
    if not os.path.exists(path): return Response("echo 'Error not found.'", mimetype='text/plain')
    with open(path, 'r', encoding='utf-8') as f: return Response(f.read(), mimetype='text/plain')


@bp.route('/api/stats')
@login_required
def get_stats_api():
    try:
        # 1. è§¦å‘æ–‡ä»¶åŒæ­¥ï¼š
        # æ­¤å‡½æ•°ä¼šæ‰§è¡Œï¼ša) DB -> local_nodes.json (ç¼“å­˜)
        #              b) local_nodes.json -> 0.yaml/1.yaml (æ–‡ä»¶ç”Ÿæˆ)
        success, message = sync_nodes_to_files() 
        
        # 2. è·å–ç»Ÿè®¡æ•°æ®
        stats = get_stats_data()
        
        # å¦‚æœæ–‡ä»¶åŒæ­¥å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªè­¦å‘ŠçŠ¶æ€ï¼Œä½†ä»å¸¦ä¸Šç»Ÿè®¡ä¿¡æ¯
        if not success:
            return jsonify({'status': 'warning', 'message': message, 'stats': stats})

        # æˆåŠŸåˆ™è¿”å›çŠ¶æ€å’Œç»Ÿè®¡æ•°æ®
        return jsonify({'status': 'success', 'stats': stats})
        
    except Exception as e:
        # å¦‚æœå‘ç”Ÿå…¶ä»–å¼‚å¸¸ï¼ˆä¾‹å¦‚ DB è¯»å–é”™è¯¯ï¼‰ï¼Œåˆ™è¿”å›é”™è¯¯
        return jsonify({'status': 'error', 'message': str(e)}), 500

@bp.route('/api/sync_files', methods=['POST'])
@login_required
def sync_files_api():
    """API: æ‰‹åŠ¨è§¦å‘åŒæ­¥"""
    success, message = sync_nodes_to_files()
    return jsonify({'status': 'success' if success else 'error', 'message': message})

# ---------------------------------------------------------
# èŠ‚ç‚¹ç®¡ç† API (ç»Ÿä¸€ç®¡ç† DB å’Œ Local)
# ---------------------------------------------------------

@bp.route('/api/nodes/list', methods=['GET'])
@login_required
def get_nodes_list_api():
    """
    API: è·å–èŠ‚ç‚¹åˆ—è¡¨
    ä¿®æ”¹ï¼šè°ƒç”¨ merge_db_to_local_json è·å–ç»Ÿä¸€åˆ—è¡¨å¹¶æŒ‰ sort_index æ’åº
    """
    try:
        nodes = merge_db_to_local_json() # è·å–æœ€æ–°åŒæ­¥æ•°æ®
        nodes.sort(key=lambda x: x.get('sort_index', 0)) # æ’åº
        
        # è¡¥å……å‰ç«¯éœ€è¦çš„è¾…åŠ©å­—æ®µ
        for node in nodes:
            # is_db å­—æ®µæ–¹ä¾¿å‰ç«¯åˆ¤æ–­å›¾æ ‡
            node['is_db'] = (node.get('origin') == 'db')
            node['is_local'] = (node.get('origin') == 'local')
            node['is_sub'] = (node.get('origin') == 'sub')
            # åè®®åˆ—è¡¨
            node['protocols'] = list(node.get('links', {}).keys())
            
        return jsonify({'status': 'success', 'nodes': nodes})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500


# ---------------------------------------------------------
# ä»è®¢é˜…è·å–èŠ‚ç‚¹å¹¶ä¿å­˜åˆ° local_nodes.json
# ---------------------------------------------------------
def run_subscription_sync(selected_ids=None, urls_override=None, triggered_by='manual'):
    entries = load_subscription_entries()
    entry_map = {entry['id']: entry for entry in entries}

    tasks = []

    def _clean_urls(raw_urls):
        if not raw_urls:
            return []
        cleaned = []
        for val in raw_urls:
            if isinstance(val, str):
                candidate = val.strip()
                if candidate:
                    cleaned.append(candidate)
        return cleaned

    if urls_override:
        url_list = _clean_urls(urls_override)
        for idx, url in enumerate(url_list):
            tasks.append({
                'id': f'temp-{idx}',
                'name': f'ä¸´æ—¶è®¢é˜… {idx + 1}',
                'url': url,
                'note': '',
                'enabled': True,
                'temporary': True
            })
    else:
        if selected_ids:
            for sid in selected_ids:
                entry = entry_map.get(sid)
                if entry and entry.get('enabled', True):
                    tasks.append(entry)
        else:
            for entry in entries:
                if entry.get('enabled', True):
                    tasks.append(entry)

    if not tasks:
        return {
            'status': 'error',
            'message': 'æ²¡æœ‰å¯ç”¨çš„è®¢é˜…é“¾æ¥',
            'reports': []
        }

    aggregated_nodes = []
    reports = []
    for entry in tasks:
        report = {
            'id': entry.get('id'),
            'alias': entry.get('name') or '',
            'url': entry.get('url'),
            'note': entry.get('note', ''),
            'status': 'pending',
            'message': '',
            'fetched': 0,
            'new': 0,
            'updated': 0,
            'errors': [],
            'trigger': triggered_by
        }

        if not entry.get('enabled', True) and not entry.get('temporary'):
            report['status'] = 'disabled'
            report['message'] = 'æ­¤è®¢é˜…å·²è¢«ç¦ç”¨'
            reports.append(report)
            continue

        url = (entry.get('url') or '').strip()
        if not url:
            report['status'] = 'error'
            report['message'] = 'URL ä¸ºç©º'
            reports.append(report)
            continue

        try:
            resp = requests.get(url, timeout=20, headers={'User-Agent': 'v2rayN/6.0'})
            resp.raise_for_status()
            content = resp.text
            extracted = extract_nodes_from_content(content)
            if extracted:
                for item in extracted:
                    item['source_id'] = entry.get('id')
                    aggregated_nodes.append(item)
                report['status'] = 'success'
                report['fetched'] = len(extracted)
                report['message'] = f'è§£æ {len(extracted)} ä¸ªèŠ‚ç‚¹'
            else:
                report['status'] = 'empty'
                report['message'] = 'è®¢é˜…å†…å®¹ä¸ºç©ºæˆ–æ— æ³•è§£æ'
        except Exception as e:
            report['status'] = 'error'
            report['message'] = 'ä¸‹è½½å¤±è´¥'
            report['errors'].append(str(e))

        reports.append(report)

    if not aggregated_nodes:
        # æ›´æ–°åŒæ­¥æ—¶é—´ï¼Œä¿å­˜çŠ¶æ€ï¼ˆå³ä¾¿å¤±è´¥ï¼‰
        now_iso = datetime.utcnow().isoformat()
        touched = False
        for report in reports:
            report['synced_at'] = now_iso
            entry = entry_map.get(report.get('id'))
            if entry:
                entry['last_synced_at'] = now_iso
                entry['last_status'] = report['status']
                entry['last_message'] = report['message']
                entry['last_trigger'] = triggered_by
                touched = True
        if touched:
            save_subscription_entries(entries)

        status_values = {r['status'] for r in reports}
        overall_status = 'error' if 'success' not in status_values else 'warning'
        overall_message = 'æœªè·å–åˆ°å¯ç”¨èŠ‚ç‚¹'
        return {
            'status': overall_status,
            'message': overall_message,
            'reports': reports,
            'synced_at': now_iso,
            'triggered_by': triggered_by
        }

    local_nodes = load_local_nodes_raw()
    new_node_names = set()
    sub_node_map = {n['name']: n for n in local_nodes if n.get('origin') == 'sub'}
    source_stats = defaultdict(lambda: {'new': 0, 'updated': 0})

    for item in aggregated_nodes:
        name = item['name']
        proto = item['protocol']
        link = item['link']
        source_id = item.get('source_id')

        new_node_names.add(name)

        if name in sub_node_map:
            target = sub_node_map[name]
            target.setdefault('links', {})[proto] = link
            if source_id:
                target['sub_source_id'] = source_id
            source_stats[source_id]['updated'] += 1
        else:
            new_node = {
                "uuid": str(uuid.uuid4()),
                "name": name,
                "links": {proto: link},
                "routing_type": -1,
                "origin": "sub",
                "is_fixed": False,
                "sort_index": 99999,
                "sub_source_id": source_id
            }
            local_nodes.append(new_node)
            sub_node_map[name] = new_node
            source_stats[source_id]['new'] += 1

    initial_count = len(local_nodes)
    local_nodes = [
        n for n in local_nodes
        if not (n.get('origin') == 'sub' and n['name'] not in new_node_names)
    ]
    count_deleted = initial_count - len(local_nodes)

    save_local_nodes(local_nodes)
    sync_nodes_to_files()

    total_new = sum(stats['new'] for stats in source_stats.values())
    total_updated = sum(stats['updated'] for stats in source_stats.values())
    synced_at_iso = datetime.utcnow().isoformat()

    # æ›´æ–°æŠ¥å‘Šä¸­çš„ new/updated å¹¶ç”Ÿæˆæ›´å‹å¥½çš„ä¿¡æ¯
    for report in reports:
        stats = source_stats.get(report.get('id'), {'new': 0, 'updated': 0})
        report['new'] = stats['new']
        report['updated'] = stats['updated']
        report['synced_at'] = synced_at_iso
        if report['status'] == 'success':
            if stats['new'] == 0 and stats['updated'] == 0:
                report['message'] = 'è§£ææˆåŠŸï¼Œä½†æœªäº§ç”Ÿå˜æ›´'
            else:
                report['message'] = f"æ–°å¢ {stats['new']}ï¼Œæ›´æ–° {stats['updated']}"

    touched = False
    for report in reports:
        entry = entry_map.get(report.get('id'))
        if entry:
            entry['last_synced_at'] = synced_at_iso
            entry['last_status'] = report['status']
            entry['last_message'] = report['message']
            entry['last_trigger'] = triggered_by
            touched = True

    if touched:
        save_subscription_entries(entries)

    overall_msg = f"åŒæ­¥å®Œæˆï¼šæ–°å¢ {total_new}ï¼Œæ›´æ–° {total_updated}"
    if count_deleted > 0:
        overall_msg += f'ï¼Œæ¸…ç†å¤±æ•ˆ {count_deleted}'

    return {
        'status': 'success',
        'message': overall_msg,
        'reports': reports,
        'summary': {
            'new': total_new,
            'updated': total_updated,
            'deleted': count_deleted
        },
        'synced_at': synced_at_iso,
        'triggered_by': triggered_by
    }

def auto_sync_subscriptions_job():
    """ä¾› APScheduler è°ƒç”¨çš„è‡ªåŠ¨åŒæ­¥ä»»åŠ¡"""
    try:
        result = run_subscription_sync(triggered_by='scheduler')
        status = result.get('status')
        msg = result.get('message')
        print(f"[Subscription-AutoSync] status={status} msg={msg}")
    except Exception as e:
        print(f"[Subscription-AutoSync] æ‰§è¡Œå¤±è´¥: {e}")

@bp.route('/api/local_nodes/fetch_from_sub', methods=['POST'])
@login_required
def fetch_from_sub_api():
    """
    API: ä»å¤–éƒ¨è®¢é˜…ä¸‹è½½å¹¶è§£æèŠ‚ç‚¹ï¼ˆæ”¯æŒå¤šè®¢é˜…ã€å®¡è®¡ä¿¡æ¯ï¼‰
    """
    try:
        data = request.get_json() or {}
        urls_override = None
        if isinstance(data.get('urls'), list):
            urls_override = data.get('urls')
        elif isinstance(data.get('urls'), str):
            urls_override = [line.strip() for line in data.get('urls').splitlines() if line.strip()]
        selected_ids = data.get('sub_ids') if isinstance(data.get('sub_ids'), list) else None

        triggered_by = 'manual'
        if current_user and getattr(current_user, 'is_authenticated', False):
            triggered_by = f'user:{current_user.username}'

        result = run_subscription_sync(selected_ids=selected_ids, urls_override=urls_override, triggered_by=triggered_by)
        status_code = 200 if result.get('status') in ['success', 'warning'] else 400
        return jsonify(result), status_code

    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@bp.route('/api/local_nodes/add', methods=['POST'])
@login_required
def add_local_node_api():
    """API: æ·»åŠ æœ¬åœ°èŠ‚ç‚¹"""
    try:
        data = request.get_json()
        name, proto, link = data.get('name'), data.get('protocol'), data.get('link')
        if not all([name, proto, link]): return jsonify({'status': 'error', 'message': 'å‚æ•°ä¸å®Œæ•´'}), 400
        
        local_nodes = load_local_nodes_raw()
        # æŸ¥æ‰¾æ˜¯å¦å­˜åœ¨åŒåæœ¬åœ°èŠ‚ç‚¹ (æ’é™¤ DB èŠ‚ç‚¹)
        target = next((n for n in local_nodes if n['name'] == name and n.get('origin') != 'db'), None)
        
        if target:
            target.setdefault('links', {})[proto] = link
            msg = f"åè®® {proto} å·²åˆå¹¶åˆ°æœ¬åœ°èŠ‚ç‚¹ {name}"
        else:
            local_nodes.append({
                "uuid": str(uuid.uuid4()),
                "name": name,
                "links": {proto: link},
                "routing_type": 1, # é»˜è®¤ç›´è¿
                "origin": "local",
                "is_fixed": False,
                "sort_index": 99999
            })
            msg = f"æœ¬åœ°èŠ‚ç‚¹ {name} å·²åˆ›å»º"
            
        save_local_nodes(local_nodes)
        return jsonify({'status': 'success', 'message': msg})
    except Exception as e: return jsonify({'status': 'error', 'message': str(e)}), 500

@bp.route('/api/local_nodes/rename', methods=['POST'])
@login_required
def rename_local_node_api():
    """
    API: é‡å‘½åèŠ‚ç‚¹
    ä¿®æ”¹ï¼šæ ¹æ® origin åˆ¤æ–­è°ƒç”¨ DB å‡½æ•°è¿˜æ˜¯ä¿®æ”¹æœ¬åœ° JSON
    """
    try:
        data = request.get_json()
        target_uuid = data.get('uuid')
        new_name = data.get('name')
        if not target_uuid or not new_name: return jsonify({'status': 'error', 'message': 'å‚æ•°ä¸å®Œæ•´'}), 400
            
        local_nodes = load_local_nodes_raw()
        target_node = next((n for n in local_nodes if n['uuid'] == target_uuid), None)
        
        if not target_node: return jsonify({'status': 'error', 'message': 'æœªæ‰¾åˆ°èŠ‚ç‚¹'}), 404
            
        if target_node.get('origin') == 'db':
            # DB èŠ‚ç‚¹ï¼šè°ƒç”¨æ•°æ®åº“æ›´æ–°
            success = update_node_custom_name(target_uuid, new_name)
            if not success: return jsonify({'status': 'error', 'message': 'æ•°æ®åº“æ›´æ–°å¤±è´¥'}), 500
        else:
            # Local èŠ‚ç‚¹ï¼šç›´æ¥æ›´æ–° JSON
            target_node['name'] = new_name
            save_local_nodes(local_nodes)
            
        sync_nodes_to_files() # é‡æ–°åŒæ­¥ä»¥åˆ·æ–°é…ç½®
        return jsonify({'status': 'success', 'message': 'é‡å‘½åæˆåŠŸ'})
    except Exception as e: return jsonify({'status': 'error', 'message': str(e)}), 500

@bp.route('/api/local_nodes/update_links', methods=['POST'])
@login_required
def update_local_node_links_api():
    """API: æ›´æ–°é“¾æ¥ (ä»…é™æœ¬åœ°èŠ‚ç‚¹)"""
    try:
        data = request.get_json()
        uuid_val, links = data.get('uuid'), data.get('links')
        local_nodes = load_local_nodes_raw()
        node = next((n for n in local_nodes if n['uuid'] == uuid_val), None)
        
        if not node: return jsonify({'status': 'error', 'message': 'èŠ‚ç‚¹ä¸å­˜åœ¨'}), 404
        # é˜²æ­¢ä¿®æ”¹ DB èŠ‚ç‚¹é“¾æ¥
        if node.get('origin') == 'db': return jsonify({'status': 'error', 'message': 'æ•°æ®åº“èŠ‚ç‚¹é“¾æ¥ä¸å¯åœ¨æ­¤ä¿®æ”¹'}), 403
        
        cleaned = {k: v for k, v in links.items() if v and v.strip()}
        if not cleaned:
            local_nodes.remove(node)
            msg = 'èŠ‚ç‚¹å·²æ¸…ç©ºå¹¶åˆ é™¤'
        else:
            node['links'] = cleaned
            msg = 'é“¾æ¥å·²æ›´æ–°'
            
        save_local_nodes(local_nodes)
        sync_nodes_to_files()
        return jsonify({'status': 'success', 'message': msg})
    except Exception as e: return jsonify({'status': 'error', 'message': str(e)}), 500

@bp.route('/api/local_nodes/delete', methods=['POST'])
@login_required
def delete_local_node_api():
    """API: åˆ é™¤èŠ‚ç‚¹ (ä»…é™æœ¬åœ°èŠ‚ç‚¹)"""
    try:
        uuid_val = request.get_json().get('uuid')
        local_nodes = load_local_nodes_raw()
        node = next((n for n in local_nodes if n['uuid'] == uuid_val), None)
        
        if not node: return jsonify({'status': 'error', 'message': 'èŠ‚ç‚¹ä¸å­˜åœ¨'}), 404
        if node.get('origin') == 'db': return jsonify({'status': 'error', 'message': 'æ— æ³•åˆ é™¤æ•°æ®åº“åŒæ­¥èŠ‚ç‚¹'}), 403
        
        local_nodes.remove(node)
        save_local_nodes(local_nodes)
        sync_nodes_to_files()
        return jsonify({'status': 'success', 'message': 'èŠ‚ç‚¹å·²åˆ é™¤'})
    except Exception as e: return jsonify({'status': 'error', 'message': str(e)}), 500

@bp.route('/api/nodes/clear_subscription', methods=['POST'])
@login_required
def clear_subscription_nodes_api():
    """
    API: æ¸…é™¤æ‰€æœ‰è®¢é˜…èŠ‚ç‚¹ (origin='sub')
    ä¿ç•™æ‰‹åŠ¨æ·»åŠ çš„ (local) å’Œæ•°æ®åº“åŒæ­¥çš„ (db) èŠ‚ç‚¹
    """
    try:
        # 1. è¯»å–å½“å‰èŠ‚ç‚¹åˆ—è¡¨
        local_nodes = load_local_nodes_raw()
        initial_count = len(local_nodes)
        
        # 2. è¿‡æ»¤åˆ—è¡¨ï¼šåªä¿ç•™ origin ä¸ä¸º 'sub' çš„èŠ‚ç‚¹
        # è¿™æ ·ä¼šæŠŠ 'sub' èŠ‚ç‚¹å…¨éƒ¨å‰”é™¤ï¼Œä¿ç•™ 'local' å’Œ 'db'
        new_nodes = [n for n in local_nodes if n.get('origin') != 'sub']
        
        deleted_count = initial_count - len(new_nodes)
        
        # 3. å¦‚æœæœ‰å˜åŒ–ï¼Œä¿å­˜å¹¶è§¦å‘åŒæ­¥
        if deleted_count > 0:
            save_local_nodes(new_nodes)
            sync_nodes_to_files() # ç«‹å³é‡æ–°ç”Ÿæˆ yamlï¼Œè®©æ›´æ”¹ç”Ÿæ•ˆ
            msg = f'å·²æ¸…é™¤ {deleted_count} ä¸ªè®¢é˜…èŠ‚ç‚¹'
        else:
            msg = 'æ²¡æœ‰å¯æ¸…é™¤çš„è®¢é˜…èŠ‚ç‚¹'
            
        return jsonify({'status': 'success', 'message': msg})
        
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@bp.route('/api/local_nodes/delete_protocol', methods=['POST'])
@login_required
def delete_local_node_protocol_api():
    """API: åˆ é™¤åè®® (ä»…é™æœ¬åœ°èŠ‚ç‚¹)"""
    try:
        data = request.get_json()
        uuid_val, proto = data.get('uuid'), data.get('protocol')
        local_nodes = load_local_nodes_raw()
        node = next((n for n in local_nodes if n['uuid'] == uuid_val), None)
        
        if not node: return jsonify({'status': 'error', 'message': 'èŠ‚ç‚¹ä¸å­˜åœ¨'}), 404
        if node.get('origin') == 'db': return jsonify({'status': 'error', 'message': 'æ— æ³•ä¿®æ”¹æ•°æ®åº“èŠ‚ç‚¹'}), 403
        
        if 'links' in node and proto in node['links']:
            del node['links'][proto]
            msg = 'åè®®å·²åˆ é™¤'
            if not node['links']:
                local_nodes.remove(node)
                msg += 'ï¼ŒèŠ‚ç‚¹ä¸ºç©ºå·²æ¸…ç†'
            save_local_nodes(local_nodes)
            sync_nodes_to_files()
            return jsonify({'status': 'success', 'message': msg})
        return jsonify({'status': 'error', 'message': 'åè®®ä¸å­˜åœ¨'}), 404
    except Exception as e: return jsonify({'status': 'error', 'message': str(e)}), 500

@bp.route('/api/nodes/update_routing', methods=['POST'])
@login_required
def update_nodes_routing_api():
    """
    API: æ›´æ–°èŠ‚ç‚¹æ’åºå’Œåˆ†ç»„
    ä¿®æ”¹ï¼šæ”¯æŒ DB èŠ‚ç‚¹çš„åˆ†ç»„ä¿®æ”¹ã€‚
    å¦‚æœæ£€æµ‹åˆ° DB èŠ‚ç‚¹çš„åˆ†ç»„(routing_type)å‘ç”Ÿå˜åŒ–ï¼Œè‡ªåŠ¨åŒæ­¥å›æ•°æ®åº“ã€‚
    """
    try:
        data = request.get_json()
        local_nodes = load_local_nodes_raw()
        node_map = {n['uuid']: n for n in local_nodes}
        
        groups = [('direct', 0), ('land', 1), ('blocked', -1)]
        current_index = 0
        
        for group_name, type_code in groups:
            uuid_list = data.get(group_name, [])
            for uuid_val in uuid_list:
                if uuid_val in node_map:
                    node = node_map[uuid_val]
                    
                    # 1. æ›´æ–°æ’åºç´¢å¼• (æ‰€æœ‰èŠ‚ç‚¹)
                    node['sort_index'] = current_index
                    current_index += 1
                    
                    # 2. æ›´æ–°åˆ†ç»„ (è·¯ç”±ç±»å‹)
                    old_type = node.get('routing_type', -1)
                    
                    # å¦‚æœåˆ†ç»„å‘ç”Ÿäº†å˜åŒ–
                    if old_type != type_code:
                        if node.get('origin') == 'db':
                            # [æ ¸å¿ƒä¿®æ”¹] DB èŠ‚ç‚¹ï¼šè°ƒç”¨æ•°æ®åº“å‡½æ•°æ›´æ–° routing_type
                            # update_node_details éœ€è¦å®Œæ•´ä¿¡æ¯ï¼Œæˆ‘ä»¬ä» local_nodes ä¸­è¯»å–å½“å‰çš„ links å’Œ name
                            success = update_node_details(
                                uuid_val, 
                                node.get('links', {}), 
                                type_code, # æ–°çš„è·¯ç”±ç±»å‹
                                node.get('name') 
                            )
                            if success:
                                node['routing_type'] = type_code
                            else:
                                print(f"Failed to update DB node routing: {uuid_val}")
                        else:
                            # Local èŠ‚ç‚¹ï¼šç›´æ¥æ›´æ–° JSON
                            node['routing_type'] = type_code
        
        # ä¿å­˜ JSON å¹¶ç”Ÿæˆé…ç½®æ–‡ä»¶
        save_local_nodes(local_nodes)
        sync_nodes_to_files()
        
        return jsonify({'status': 'success', 'message': 'æ’åºä¸åˆ†ç»„å·²æ›´æ–° (DBå·²åŒæ­¥)'})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@bp.route('/base64/all')
def download_v2ray_base64():
    """ä¸‹è½½ Base64 è®¢é˜…"""
    verify_request_token()
    # 1. ç»Ÿä¸€ä» merged åˆ—è¡¨è·å–æ‰€æœ‰èŠ‚ç‚¹
    all_nodes = merge_db_to_local_json()
    # 2. å…è®¸ç›´è¿(0)ã€è½åœ°(1)ï¼Œä»¥åŠå°šæœªåˆ†ç±»çš„è®¢é˜…èŠ‚ç‚¹ (routing_type=-1 æˆ– None)
    # é¿å…ç”¨æˆ·å°šæœªæ‰‹åŠ¨åˆ†ç»„æ—¶è®¢é˜…å†…å®¹ä¸ºç©º
    nodes_to_include = []
    for node in all_nodes:
        r_type = node.get('routing_type')
        if r_type in [0, 1]:
            nodes_to_include.append(node)
            continue
        if node.get('origin') == 'sub' and (r_type is None or r_type == -1):
            nodes_to_include.append(node)

    # 3. æŒ‰ sort_index æ’åº
    nodes_to_include.sort(key=lambda x: x.get('sort_index', 0))
    links = []
    for node in nodes_to_include:
        links_dict = node.get('links', {})
        name = node.get('name', 'Unknown')
        origin = node.get('origin', 'local')
        region = node.get('region', 'LOC')
        
        # å¢åŠ å¯¹ç±»å‹çš„å›¾æ ‡åˆ¤æ–­
        flag = get_emoji_flag(region) if origin == 'db' else ('ğŸ“' if origin == 'local' else '')
        for proto, link in links_dict.items():
            if link and link.strip():
                # 2. è®¡ç®— name_prefix (åœ¨åè®®å¾ªç¯å†…ï¼Œä½¿ç”¨å½“å‰çš„ proto)
                name_prefix = ""
                if origin == 'db' or origin == 'local':
                    # åªæœ‰ DB å’Œ Local èŠ‚ç‚¹éœ€è¦åè®®å‰ç¼€
                    name_prefix = f"{proto.lower()}-"
                # origin == 'sub' æ—¶ï¼Œname_prefix ä¿æŒç©ºå­—ç¬¦ä¸²
                
                link = fix_link_ipv6(link) # æé«˜å¯¹ipv6çš„å…¼å®¹æ€§
                
                # 3. æ„é€ æœ€ç»ˆåç§°
                full_name = f"{flag} {name_prefix}{name}".strip()
                
                safe_name = urllib.parse.quote(full_name)
                if '#' in link: link = link.split('#')[0]
                links.append(f"{link}#{safe_name}")

    joined = "\n".join(links)
    # å¦‚æœä¼ å…¥ ?raw=1 åˆ™ç›´æ¥è¿”å›åŸå§‹æ–‡æœ¬ï¼Œä¾¿äºè°ƒè¯•
    try:
        raw_flag = str(request.args.get('raw', '')).lower() in ['1', 'true', 'yes']
    except Exception:
        raw_flag = False

    if raw_flag:
        return Response(joined, mimetype='text/plain; charset=utf-8')

    b64 = base64.b64encode(joined.encode('utf-8')).decode('utf-8')
    return Response(b64, mimetype='text/plain')

@bp.route('/api/callback/add_node', methods=['POST'])
def add_node_callback():
    """API: è„šæœ¬å›è°ƒè‡ªåŠ¨æ·»åŠ èŠ‚ç‚¹ (è§†ä¸º Local èŠ‚ç‚¹)"""
    try:
        data = request.get_json()
        name, proto, link = data.get('name'), data.get('protocol'), data.get('link')
        if not all([name, proto, link]): return jsonify({'status': 'error', 'message': 'Missing data'}), 400
        
        local_nodes = load_local_nodes_raw()
        target = next((n for n in local_nodes if n['name'] == name and n.get('origin') == 'local'), None)
        
        if target:
            target.setdefault('links', {})[proto] = link
            msg = f"å·²åˆå¹¶åˆ°èŠ‚ç‚¹ {name}"
        else:
            local_nodes.append({
                "uuid": str(uuid.uuid4()),
                "name": name,
                "links": {proto: link},
                "routing_type": 1,
                "origin": "local",
                "is_fixed": False,
                "sort_index": 99999
            })
            msg = f"è‡ªåŠ¨æ·»åŠ èŠ‚ç‚¹ {name}"
        save_local_nodes(local_nodes)
        sync_nodes_to_files()
        return jsonify({'status': 'success', 'message': msg})
    except Exception as e: return jsonify({'status': 'error', 'message': str(e)}), 500

@bp.route('/raw/<int:routing_type>')
def download_raw_subscription(routing_type):
    verify_request_token()
    filename = '0.yaml' if routing_type == 0 else '1.yaml'
    path = os.path.join(get_nodes_dir(), filename)
    if not os.path.exists(path): sync_nodes_to_files()
    content = "proxies: []"
    if os.path.exists(path):
        with open(path, 'r', encoding='utf-8') as f: content = f.read()
    resp = make_response(content)
    resp.mimetype = "text/yaml; charset=utf-8"
    resp.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
    return resp

@bp.route('/list/<list_type>')
def download_rule_list(list_type):
    verify_request_token()
    filename = 'direct.list' if list_type == 'direct' else 'customize.list'
    path = os.path.join(get_nodes_dir(), filename)
    if not os.path.exists(path): path += '.txt'
    if os.path.exists(path):
        with open(path, 'r', encoding='utf-8') as f: return Response(f.read(), mimetype='text/plain')
    return "", 404

@bp.route('/api/rules', methods=['GET', 'POST'])
@login_required
def handle_rules():
    filename = request.args.get('file')
    if filename not in ['direct.list', 'customize.list', 'install-singbox.sh']: return jsonify({'error': 'invalid'}), 400
    path = os.path.join(get_nodes_dir(), filename)
    if request.method == 'GET':
        if not os.path.exists(path): return jsonify({'content': ''})
        with open(path, 'r', encoding='utf-8') as f: return jsonify({'status': 'success', 'content': f.read()})
    else:
        content = request.get_json().get('content', '')
        if filename.endswith('.sh'): content = content.replace('\r\n', '\n')
        with open(path, 'w', encoding='utf-8') as f: f.write(content)
        return jsonify({'status': 'success'})

@bp.route('/api/rule_template', methods=['GET', 'POST'])
@login_required
def handle_rule_template():
    path = os.path.join(get_nodes_dir(), 'clash_meta.yaml')
    if request.method == 'GET':
        if not os.path.exists(path): return jsonify({'content': ''})
        with open(path, 'r', encoding='utf-8') as f: return jsonify({'status': 'success', 'content': f.read()})
    else:
        with open(path, 'w', encoding='utf-8') as f: f.write(request.get_json().get('content', ''))
        return jsonify({'status': 'success'})
